{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b9f70ac",
   "metadata": {},
   "source": [
    "# Uploading on Google Colab to train model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87970aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c66d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = '/content/gdrive/My Drive/DIP1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed289305",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /content/gdrive/My\\ Drive/DIP1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c0f6aa",
   "metadata": {},
   "source": [
    "# Installing Ultralytics for Yolov8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b87d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1076cda",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a56f175",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"yolov8n.yaml\")  # build a new model from scratch\n",
    "\n",
    "# Use the model\n",
    "results = model.train(data=os.path.join(ROOT_DIR, \"colab_config.yaml\"), epochs=50, project=\"/content/runs\", batch = 8, lr0=0.001)  # train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb54a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "import time\n",
    "\n",
    "source = '/content/runs'\n",
    "destination = '/content/gdrive/My Drive/DIP1/runs/detect'\n",
    "\n",
    "os.makedirs(destination, exist_ok=True)\n",
    "\n",
    "try:\n",
    "    shutil.copytree(source, destination, dirs_exist_ok=True)\n",
    "    print(f\"Directory copied successfully from {source} to {destination}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error occurred while copying: {e}\")\n",
    "\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6ea347",
   "metadata": {},
   "source": [
    "# Testing model on a picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc34d679",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "model = YOLO('runs/detect/train(81)/weights/best.pt')  \n",
    "\n",
    "image_path = os.path.join('data', 'images', 'L0241.png')\n",
    "img = cv2.imread(image_path)\n",
    "results = model(img)\n",
    "\n",
    "annotated_img = results[0].plot()\n",
    "\n",
    "cv2.imshow(\"YOLOv8 Detection\", annotated_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff841c7",
   "metadata": {},
   "source": [
    "# Installing necessary dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcac6874",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7780b7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0418a83b",
   "metadata": {},
   "source": [
    "# Installing pygame to play sound when performing real time detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bf0b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0626097d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pygame check:\n",
    "import pygame\n",
    "import os\n",
    "import time\n",
    "\n",
    "pygame.mixer.init()\n",
    "\n",
    "alert_sound_path = 'alert.mp3'\n",
    "\n",
    "\n",
    "def play_alert_sound():\n",
    "    if os.path.exists(alert_sound_path):\n",
    "        print(f\"Playing sound from: {alert_sound_path}\")\n",
    "        pygame.mixer.music.load(alert_sound_path)\n",
    "        pygame.mixer.music.play()\n",
    "    else:\n",
    "        print(\"Error: Alert sound file not found!\")\n",
    "\n",
    "\n",
    "play_alert_sound()\n",
    "\n",
    "\n",
    "timeout = 10\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "while pygame.mixer.music.get_busy() and (time.time() - start_time < timeout):\n",
    "    time.sleep(0.1)\n",
    "\n",
    "if time.time() - start_time >= timeout:\n",
    "    print(f\"Timeout reached: {timeout} seconds. Stopping sound.\")\n",
    "    pygame.mixer.music.stop()\n",
    "\n",
    "print(\"Test finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2da000",
   "metadata": {},
   "source": [
    "# Utilising HaarCascade (For better Face Detection) + Pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f5c1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import time\n",
    "from ultralytics import YOLO\n",
    "import threading\n",
    "import pygame\n",
    "import os\n",
    "\n",
    "# Initialize Pygame mixer for sound playback\n",
    "pygame.mixer.init()\n",
    "\n",
    "alert_sound_path = 'alert.mp3'\n",
    "\n",
    "model = YOLO(r'D:\\School Work\\College\\DIP\\Drowsiness\\Drowsiness\\runs\\detect\\train(81)\\weights\\last.pt')\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "def play_alert_sound():\n",
    "    if os.path.exists(alert_sound_path):\n",
    "        print(f\"Playing sound from: {alert_sound_path}\")\n",
    "        pygame.mixer.music.load(alert_sound_path)\n",
    "        pygame.mixer.music.play()\n",
    "    else:\n",
    "        print(\"Error: Alert sound file not found!\")\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 320)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 320)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open webcam.\")\n",
    "    exit()\n",
    "\n",
    "class VideoStream:\n",
    "    def __init__(self, src=0):\n",
    "        self.stream = cv2.VideoCapture(src)\n",
    "        (self.grabbed, self.frame) = self.stream.read()\n",
    "        self.stopped = False\n",
    "        self.lock = threading.Lock()\n",
    "\n",
    "    def start(self):\n",
    "        threading.Thread(target=self.update, args=()).start()\n",
    "        return self\n",
    "\n",
    "    def update(self):\n",
    "        while not self.stopped:\n",
    "            (grabbed, frame) = self.stream.read()\n",
    "            with self.lock:\n",
    "                self.grabbed = grabbed\n",
    "                self.frame = frame\n",
    "\n",
    "    def read(self):\n",
    "        with self.lock:\n",
    "            frame = self.frame.copy()\n",
    "        return frame\n",
    "\n",
    "    def stop(self):\n",
    "        self.stopped = True\n",
    "        self.stream.release()\n",
    "\n",
    "vs = VideoStream().start()\n",
    "\n",
    "while True:\n",
    "    frame = vs.read()\n",
    "\n",
    "    if frame is None:\n",
    "        print(\"Error: Failed to capture image.\")\n",
    "        break\n",
    "\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = face_cascade.detectMultiScale(gray_frame, scaleFactor=1.1, minNeighbors=5)\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        face_roi = frame[y:y+h, x:x+w]\n",
    "\n",
    "        face_resized = cv2.resize(face_roi, (320, 320))\n",
    "\n",
    "        results = model.predict(face_resized, conf=0.7, iou=0.5)\n",
    "\n",
    "        if results and len(results[0].boxes) > 0:\n",
    "            print(\"Face detected! Playing alert sound.\")\n",
    "            sound_thread = threading.Thread(target=play_alert_sound)\n",
    "            sound_thread.start()\n",
    "\n",
    "        annotated_face = results[0].plot()\n",
    "        if annotated_face.shape[2] == 1:\n",
    "            annotated_face = cv2.cvtColor(annotated_face, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "        annotated_face_resized = cv2.resize(annotated_face, (w, h))\n",
    "\n",
    "        frame[y:y+h, x:x+w] = annotated_face_resized\n",
    "\n",
    "    cv2.imshow(\"Face Detection with YOLOv8\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "vs.stop()\n",
    "cv2.destroyAllWindows()\n",
    "pygame.mixer.music.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
